# -*- coding: utf-8 -*-
"""CalculateErrorRate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qqreJYkrOaJ2hpfDDYzaytYJoVg_ZJkm
"""

import pandas as pd
from sklearn.metrics import confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis

from google.colab import drive
drive.mount('/content/drive/')

#Error rate calculation for Linear Regression as a Classifier 

source_path = '/content/drive/My Drive/PA_3/FCV/'
error_lst = []
total = 0
#Taking one fold at a time: 
for i in range(1,11):
   
  #loading training data
    train_data = pd.read_csv(source_path + 'train' +str(i) + '.csv')
    train_Y = train_data.iloc[:,-1]
    train_X = train_data.iloc[:,0:-1]
    
    
  #loading test data
    test_data = pd.read_csv(source_path + 'test' +str(i) + '.csv')
    test_Y = test_data.iloc[:,-1]
    test_X = test_data.iloc[:,0:-1]
    
  #selecting linear regression for classification 
    classifier = LogisticRegression(solver= 'liblinear', multi_class = 'ovr')
     
  #creating predictor model from the training data
    classifier.fit(train_X, train_Y)
    
  #testing the fit on the test dataset
    predicted = classifier.predict(test_X)
    
  #creating confusion matrix for required matix for error calculation
    confusion = confusion_matrix(test_Y, predicted)
    
  #the misclassified data are included in false positives and false negatives
    fp = confusion[0, 1]
    fn = confusion[1, 0]
    
  #calcualting the misclassification rate or the error rate for predictor model
    error_rate = (fp+fn)/len(test_Y)*100
    print('Error in fold CV%d = %f' %(i, error_rate) )
    
  #adding all the error rates to a variable 
    total += error_rate
    
#Calculating the average from the sum of all the errors   
print ("Average Error Rate = %s" %(total/10))

#Error rate calculation for Linear Discriminant Analysis as a Classifier 

source_path = '/content/drive/My Drive/PA_3/10Folds/'
error_lst = []
total = 0
#Taking one fold at a time: 
for i in range(1,11):
   
  #loading training data
    train_data = pd.read_csv(source_path + 'train' +str(i) + '.csv')
    train_Y = train_data.iloc[:,-1]
    train_X = train_data.iloc[:,0:-1]
    
    
  #loading test data
    test_data = pd.read_csv(source_path + 'test' +str(i) + '.csv')
    test_Y = test_data.iloc[:,-1]
    test_X = test_data.iloc[:,0:-1]
    
    
  #selecting Linear Discriminant Analysis for classification 
    classifier = LinearDiscriminantAnalysis()
     
  #creating predictor model from the training data
    classifier.fit(train_X, train_Y)
    
  #testing the fit on the test dataset
    predicted = classifier.predict(test_X)
    
  #creating confusion matrix for required matix for error calculation
    confusion = confusion_matrix(test_Y, predicted)
    
  #the misclassified data are included in false positives and false negatives
    fp = confusion[0, 1]
    fn = confusion[1, 0]
    
  #calcualting the misclassification rate or the error rate for predictor model
    error_rate = (fp+fn)/len(test_Y)*100
    print('Error in fold CV%d = %f' %(i, error_rate) )
    
  #adding all the error rates to a variable 
    total += error_rate
    
#Calculating the average from the sum of all the errors   
print ("Average Error Rate = %s" %(total/10))

#Error rate calculation for Quadratic Discriminant Analysis as a Classifier

source_path = '/content/drive/My Drive/PA_3/10Folds/'
error_lst = []
total = 0
#Taking one fold at a time: 
for i in range(1,11):
   
  #loading training data
    train_data = pd.read_csv(source_path + 'train' +str(i) + '.csv')
    train_Y = train_data.iloc[:,-1]
    train_X = train_data.iloc[:,0:-1]
    
    
  #loading test data
    test_data = pd.read_csv(source_path + 'test' +str(i) + '.csv')
    test_Y = test_data.iloc[:,-1]
    test_X = test_data.iloc[:,0:-1]
    
    
  #selecting Quadratic Discriminant Analysis for classification 
    classifier = QuadraticDiscriminantAnalysis()
    
     
  #creating predictor model from the training data
    classifier.fit(train_X, train_Y)
    
  #testing the fit on the test dataset
    predicted = classifier.predict(test_X)
    
  #creating confusion matrix for required matix for error calculation
    confusion = confusion_matrix(test_Y, predicted)
    
  #the misclassified data are included in false positives and false negatives
    fp = confusion[0, 1]
    fn = confusion[1, 0]
    
  #calcualting the misclassification rate or the error rate for predictor model
    error_rate = (fp+fn)/len(test_Y)*100
    print('Error in fold CV%d = %f' %(i, error_rate) )
    
  #adding all the error rates to a variable 
    total += error_rate
    
#Calculating the average from the sum of all the errors   
print ("Average Error Rate = %s" %(total/10))